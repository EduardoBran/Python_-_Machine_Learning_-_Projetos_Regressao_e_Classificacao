{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97fdd27-8b19-4f8c-adfa-b7655b0bf035",
   "metadata": {},
   "source": [
    "# <span style=\"color: green; font-size: 40px; font-weight: bold;\"> Projeto: Classificação de Imagens de Animais</span>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# Contexto\n",
    "\n",
    "- Em uma pequena cidade rodeada por florestas exuberantes, vivia Júlia, uma jovem bióloga apaixonada pela fauna local. Júlia trabalhava em um centro de conservação de animais, onde sua principal responsabilidade era monitorar as populações de diferentes espécies na região. Com o passar do tempo, ela percebeu que a quantidade de dados visuais que acumulava estava se tornando incontrolável. Havia milhares de fotos de câmeras de vigilância espalhadas pela floresta, capturando imagens de diversas espécies de animais dia e noite.\n",
    "\n",
    "- A análise manual dessas imagens era um processo demorado e propenso a erros. Muitas vezes, Júlia e seus colegas passavam horas tentando identificar corretamente as espécies nas fotos. Isso não apenas atrasava os relatórios, mas também comprometia a precisão dos dados coletados, impactando negativamente os esforços de conservação.\n",
    "\n",
    "- Cansada dos desafios enfrentados, Júlia decidiu que era hora de trazer tecnologia ao seu trabalho. Ela ouviu falar sobre a inteligência artificial e como poderia ser usada para automatizar tarefas de classificação de imagens. Com essa ideia em mente, Júlia se inscreveu em um curso de Data Science e Machine Learning, onde aprendeu sobre redes neurais convolucionais (CNNs) e sua capacidade de processar imagens de forma eficiente.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Criação do Projeto\n",
    "\n",
    "- Depois de adquirir o conhecimento necessário, Júlia decidiu criar um projeto de classificação de imagens de animais. Ela sabia que isso não só iria ajudar em seu trabalho, mas também poderia ser uma contribuição significativa para a comunidade científica.\n",
    "\n",
    "- Júlia começou o projeto baixando um conjunto de dados de imagens de animais disponíveis no Kaggle, conhecido como \"Animal-10 dataset\". Este conjunto de dados continha milhares de imagens de 10 diferentes espécies de animais, proporcionando uma base robusta para treinar seu modelo de classificação.\n",
    "\n",
    "### Passos do Projeto\n",
    "\n",
    "- Coleta de Dados: Júlia carregou todas as imagens do diretório e associou os rótulos correspondentes.\n",
    "- Análise dos Dados: Antes de prosseguir, ela realizou uma análise preliminar para garantir que os dados estavam corretos e prontos para o pré-processamento.\n",
    "- Pré-processamento dos Dados: Ela normalizou as imagens e codificou os rótulos para preparar os dados para o modelo de machine learning.\n",
    "- Criação do Modelo: Júlia construiu uma rede neural convolucional (CNN) utilizando Keras para processar e classificar as imagens.\n",
    "- Treinamento do Modelo: Com os dados prontos, ela treinou o modelo e validou seu desempenho.\n",
    "- Avaliação do Modelo: Júlia avaliou a precisão do modelo utilizando os dados de teste, ajustando conforme necessário para melhorar o desempenho.\n",
    "- Salvamento e Carregamento do Modelo: Após treinar o modelo com sucesso, ela salvou o modelo para uso futuro.\n",
    "- Previsões com Novas Imagens: Júlia implementou um método para carregar e prever a classe de novas imagens capturadas pelas câmeras de vigilância.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "- O modelo de Júlia deve classificar as espécies de animais com alta precisão, automatizando um processo que antes era feito manualmente. Isso permitirá que Júlia e sua equipe dedicassem mais tempo a outras tarefas importantes e melhorassem a eficiência e a precisão dos esforços de conservação.\n",
    "\n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a76a531-1808-4530-9243-0185fb6671f8",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Importando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82533453-6835-4dbe-8320-e94771f7e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c4bae7-9676-4520-bfa0-22b2b32ccdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 22:35:08.635514: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-06-09 22:35:08.635531: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28d6c4-db57-4de2-8f7f-4888a621ebab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96931688-080a-41a6-a07b-1c57a330ce29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225afb2-ccd2-4f3c-bd05-f6db4e36d0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a923fb27-37d8-4933-8ec7-2e27bceca885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c01af8-073c-485b-b502-2bf83a02b716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.19.5\n",
      "TensorFlow version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90478ae2-6c32-4f60-a4ad-e2278302c077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30fda4d-7d4b-42c4-9019-464a5aba2607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4165447-c17d-4750-8296-187e53a6a38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805eb29-7290-4ba7-9d5e-95aea6a580b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c3671c-16f6-4e43-b06d-6fab243a418c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90e989e4-a77f-4787-b00c-13e9cbb27605",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "Passo 1: Coleta de Dados\n",
    "Comentário: Carregamos as imagens e rótulos do diretório do conjunto de dados.\n",
    "\n",
    "python\n",
    "Copiar código\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_images(directory, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        if os.path.isdir(os.path.join(directory, label)):\n",
    "            for file in os.listdir(os.path.join(directory, label)):\n",
    "                img = load_img(os.path.join(directory, label, file), target_size=target_size)\n",
    "                img_array = img_to_array(img)\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "data_dir = 'path/to/animals10'\n",
    "images, labels = load_images(data_dir)\n",
    "Análise dos Dados\n",
    "Comentário: Realizamos uma análise preliminar dos dados para verificar se estão corretos e prontos para o pré-processamento.\n",
    "\n",
    "python\n",
    "Copiar código\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Verificar as dimensões dos dados\n",
    "print(f'Total de imagens: {images.shape[0]}')\n",
    "print(f'Dimensão de cada imagem: {images.shape[1:]}')\n",
    "print(f'Total de rótulos: {len(labels)}')\n",
    "\n",
    "# Verificar a distribuição dos rótulos\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=unique_labels, y=counts)\n",
    "plt.title('Distribuição de Rótulos')\n",
    "plt.xlabel('Classes de Animais')\n",
    "plt.ylabel('Número de Imagens')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar algumas imagens\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(images[i].astype('uint8'))\n",
    "    plt.title(labels[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "Passo 2: Pré-processamento de Dados\n",
    "Comentário: Carregamos e rotulamos as imagens do diretório, além de normalizar e codificar os rótulos.\n",
    "\n",
    "python\n",
    "Copiar código\n",
    "# Encode the labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)\n",
    "Passo 3: Normalização dos Dados\n",
    "Comentário: Normalizamos os dados e realizamos a codificação one-hot dos rótulos.\n",
    "\n",
    "python\n",
    "Copiar código\n",
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "Passo 4: Criação do Modelo\n",
    "Comentário: Construímos o modelo de rede neural convolucional (CNN) utilizando Keras.\n",
    "\n",
    "python\n",
    "Copiar código\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(labels)), activation='softmax')\n",
    "])\n",
    "Passo 5: Compilação do Modelo\n",
    "Comentário: Compilamos o modelo com o otimizador Adam e a função de perda categorical crossentropy.\n",
    "\n",
    "python\n",
    "Copiar código\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "Passo 6: Treinamento do Modelo\n",
    "Comentário: Treinamos o modelo com os dados de treinamento e validamos com os dados de teste.\n",
    "\n",
    "python\n",
    "Copiar código\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "Passo 7: Avaliação do Modelo\n",
    "Comentário: Avaliamos o desempenho do modelo utilizando os dados de teste.\n",
    "\n",
    "python\n",
    "Copiar código\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "Passo 8: Salvando e Carregando o Modelo\n",
    "Comentário: Salvamos o modelo treinado em um arquivo e carregamos o modelo para uso futuro.\n",
    "\n",
    "python\n",
    "Copiar código\n",
    "# Salvar o modelo\n",
    "model.save('animal_classifier_model.h5')\n",
    "\n",
    "# Carregar o modelo\n",
    "from keras.models import load_model\n",
    "model = load_model('animal_classifier_model.h5')\n",
    "Passo 9: Previsões com Novas Imagens\n",
    "Comentário: Utilizamos o modelo para prever a classe de novas imagens. As novas imagens também precisam ser pré-processadas antes de serem passadas para o modelo.\n",
    "\n",
    "python\n",
    "Copiar código\n",
    "def predict_image(image_path, model, target_size=(128, 128)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "    return predicted_label[0]\n",
    "\n",
    "# Exemplo de uso\n",
    "image_path = 'path/to/new/image.jpg'\n",
    "print(predict_image(image_path, model))\n",
    "Resumo\n",
    "Este projeto orienta você através das etapas para criar um modelo de classificação de imagens usando deep learning. Começamos verificando e instalando pacotes necessários, fornecemos o link para o download do conjunto de dados, realizamos uma análise preliminar para garantir a qualidade dos dados, e passamos pelo pré-processamento, construção, treinamento, avaliação e salvamento do modelo. No final, mostramos como prever a classe de novas imagens, garantindo que elas sejam pré-processadas adequadamente antes de serem passadas para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b058a-92e6-4915-b602-8c0aa494928e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
